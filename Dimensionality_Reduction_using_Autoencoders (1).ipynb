{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFKaemeRcdeJ"
      },
      "outputs": [],
      "source": [
        "#Step 1 – Importing all required libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Use pandas to read in the csv file called anonymized_data.csv . It contains 500 rows and 30 columns of anonymized data along with 1 last column with a classification label, where the columns have been renamed to 4 letter codes.**"
      ],
      "metadata": {
        "id": "ilTr3Ua7c-Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 – Reading our input data.\n",
        "data = pd.read_csv('/content/anonymized_data.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "7FCA2Iikc_92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 30 feature columns and 1 Label column in our dataset.\n",
        "These feature columns are anonymous."
      ],
      "metadata": {
        "id": "C1qwkUj3fb64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 – Checking info of our data."
      ],
      "metadata": {
        "id": "htFjs71PflAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the stats below that we don’t have any null values in our data."
      ],
      "metadata": {
        "id": "UK676AVdfsDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "dxNN6TUpdJIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 – Scaling our data for Dimensionality Reduction using Autoencoders."
      ],
      "metadata": {
        "id": "pEnBkp21fzno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data.drop('Label',axis=1))\n",
        "scaled_data.shape"
      ],
      "metadata": {
        "id": "LEVaucYjdMWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using MinMaxScaler here to scale our data.\n",
        "Also here we are checking the shape of our data.\n",
        "While scaling we dropped the Label column as shown above."
      ],
      "metadata": {
        "id": "EO8Lcnbtf2H7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 – Defining no. of nodes in layers."
      ],
      "metadata": {
        "id": "efjZsHPqf5Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_inputs = 30\n",
        "num_hidden = 2\n",
        "num_outputs = num_inputs # Must be true for an autoencoder!"
      ],
      "metadata": {
        "id": "92moiXNxdMZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6 – Building the model for Dimensionality Reduction using Autoencoders."
      ],
      "metadata": {
        "id": "9mjpEPxBf8b4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(num_inputs, input_shape=[num_inputs]))\n",
        "model.add(Dense(num_hidden))\n",
        "model.add(Dense(num_outputs))\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), metrics=['accuracy'], loss='mae')\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "Tvb3AYqJdMcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "We have a very simple model for this use case.\n",
        "We have 3 layers.\n",
        "The first layer is having 30 nodes, 2nd is having 2 nodes and the third is also having 30 nodes.\n",
        "Our input and output nodes should show the same type of data when building Autoencoders."
      ],
      "metadata": {
        "id": "mUSEViQwgATV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Now plot out the reduced dimensional representation of the data. Do you still have clear separation of classes even with the reduction in dimensions? Hint: You definitely should, the classes should still be clearly seperable, even when reduced to 2 dimensions. **"
      ],
      "metadata": {
        "id": "0TBhPEyxdUIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7 – Let’s train the model for Dimensionality Reduction using Autoencoders."
      ],
      "metadata": {
        "id": "Et0LHq9TgEt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=scaled_data, y=scaled_data, epochs=1000, batch_size=32)"
      ],
      "metadata": {
        "id": "bXSeVoQrdMen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8 – Take the output from the middle layer."
      ],
      "metadata": {
        "id": "6fx8lGQMgIPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(index=1).output)\n",
        "intermediate_output = intermediate_layer_model.predict(scaled_data)"
      ],
      "metadata": {
        "id": "o2r6QydMdMii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can’t just directly take the output from our middle layer.\n",
        "That’s why we need to create a model, with just 1 layer which will be our middle layer.\n",
        "model.get_layer(index=1) is extracting the middle layer from our original model and .output is used for taking its output.\n",
        "In the second line, we are simply using predict to take the results from the 2nd layer."
      ],
      "metadata": {
        "id": "D7HBnFNcgMLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intermediate_output.shape"
      ],
      "metadata": {
        "id": "_QnXRmwidMmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9 – Checking the output shape of our result."
      ],
      "metadata": {
        "id": "KWifE7wwgPaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see below that the shape of the intermediate output became 500X2 means 30 columns/features are now suppressed to only 2 columns/features."
      ],
      "metadata": {
        "id": "uAz-JLdtgSy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10 – Plotting our results for Dimensionality Reduction using Autoencoders."
      ],
      "metadata": {
        "id": "CYoE7qlOgWIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=intermediate_output[:,0], y=intermediate_output[:,1], hue=data['Label'])\n"
      ],
      "metadata": {
        "id": "4uYFwabTdvNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And BOOM here is the result.\n",
        "The amount of data our 30 features were showing, we are able to show that data precisely using just these 2 dimensions.\n",
        "Both classes are linearly separable, which means our model did a good job of keeping the essence of the data."
      ],
      "metadata": {
        "id": "7LzlrWgage2y"
      }
    }
  ]
}